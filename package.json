{
    "name": "@webstandard/robots",
    "version": "1.0.0",
    "homepage": "https://alexstevovich.com/r/webstandard-robots-nodejs",
    "author": {
        "name": "Alex Stevovich",
        "email": "alex.stevovich@gmail.com",
        "url": "https://alexstevovich.com"
    },
    "description": "A standards-compliant generator for producing robots.txt files",
    "type": "module",
    "main": "./src/index.js",
    "files": [
        "./src"
    ],
    "license": "Apache-2.0",
    "scripts": {
        "poshify": "npx poshify",
        "pretty": "npx prettier --write .",
        "lint": "eslint ./src/",
        "lint:fix": "eslint --fix ./src/",
        "test": "npx vitest --run",
        "build": "npm run poshify && npm run pretty && npm run lint:fix && npm run lint"
    },
    "keywords": [
        "robots.txt",
        "robots",
        "sitemap",
        "seo",
        "search-engines",
        "crawler",
        "crawl-rules",
        "fluent-api",
        "javascript",
        "web",
        "automation",
        "web-crawling",
        "web-scraping",
        "site-indexing",
        "robots-txt-generator"
    ],
    "devDependencies": {
        "eslint": "^9.36.0",
        "eslint-plugin-import": "^2.32.0",
        "eslint-plugin-prettier": "^5.5.4",
        "poshify": "^1.0.0",
        "prettier": "^3.6.2",
        "vitest": "^3.2.4"
    }
}
